{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cde750-8ccd-434f-82f8-94e84d6a6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f0dc7-21c5-4531-a5c2-6790849cf78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using JSON\n",
    "\n",
    "using DataIO\n",
    "using GCTGMT\n",
    "using Support\n",
    "\n",
    "using FeatureSetEnrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b9f6c-7b69-4449-870c-a9878716d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "benchmarks_directory_path = \"/Users/kwat/Downloads/score_and_set/\"\n",
    "\n",
    "#\n",
    "benchmark_ = []\n",
    "\n",
    "#\n",
    "method_ = []\n",
    "\n",
    "for m in keys(score_set_new([\"a\", \"b\"], [-1.0, 1.0], [\"a\"]; plot = false))\n",
    "\n",
    "    push!(method_, string(m, \" extreme\"), string(m, \" area\"))\n",
    "\n",
    "end\n",
    "\n",
    "method_ = String.(method_)\n",
    "\n",
    "n_method = length(method_)\n",
    "\n",
    "#\n",
    "benchmark_x_method_rows = []\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f31f7-e680-47d3-8770-80ae40fffe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in readdir(benchmarks_directory_path)\n",
    "    \n",
    "    #\n",
    "    if name[1] == '.'\n",
    "\n",
    "        continue\n",
    "\n",
    "    end\n",
    "\n",
    "    println(name)\n",
    "\n",
    "    #\n",
    "    benchmark_directory_path = joinpath(benchmarks_directory_path, name)\n",
    "\n",
    "    element_, score_ =\n",
    "        eachcol(read_data(joinpath(benchmark_directory_path, \"gene_x_score.tsv\")))\n",
    "\n",
    "    json_dict = convert(\n",
    "        Dict{String,Vector{String}},\n",
    "        JSON.parse(open(joinpath(benchmark_directory_path, \"gene_set.json\"))),\n",
    "    )\n",
    "\n",
    "    #\n",
    "    set_to_element_ = read_gmt(\n",
    "        map(\n",
    "            gmt_path -> replace(gmt_path, \"..\" => \"/Users/kwat/Downloads/\"),\n",
    "            json_dict[\"gene_sets_tested\"],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    set_ = sort(collect(keys(set_to_element_)))\n",
    "\n",
    "    n_set = length(set_)\n",
    "\n",
    "    #\n",
    "    set_to_method_to_result = score_set_new(element_, score_, set_to_element_)\n",
    "\n",
    "    #\n",
    "    set_x_method = Matrix(undef, n_set, n_method)\n",
    "\n",
    "    for (set_i, (set, method_to_result)) in enumerate(set_to_method_to_result)\n",
    "\n",
    "        set_x_method_row = []\n",
    "\n",
    "        for result in values(method_to_result)\n",
    "\n",
    "            append!(set_x_method_row, result[2:3])\n",
    "\n",
    "        end\n",
    "\n",
    "        set_x_method[set_i, :] = set_x_method_row\n",
    "\n",
    "    end\n",
    "\n",
    "    #\n",
    "    for set in json_dict[\"gene_sets_positive\"]\n",
    "\n",
    "        #\n",
    "        print(\"    \")\n",
    "\n",
    "        if in(set, set_)\n",
    "\n",
    "            println(set)\n",
    "\n",
    "        else\n",
    "\n",
    "            println(set, \" (missing)\")\n",
    "\n",
    "            continue\n",
    "\n",
    "        end\n",
    "\n",
    "        #\n",
    "        push!(benchmark_, string(name, '.', set))\n",
    "\n",
    "        #\n",
    "        benchmark_x_method_row = []\n",
    "\n",
    "        for (method_i, set_score_) in enumerate(eachcol(set_x_method))\n",
    "\n",
    "            set_score_, set_ = sort_like((Float64.(set_score_), set_))\n",
    "\n",
    "            push!(benchmark_x_method_row, findfirst(set_ .== set) / n_set)\n",
    "\n",
    "        end\n",
    "\n",
    "        push!(benchmark_x_method_rows, Float64.(benchmark_x_method_row))\n",
    "\n",
    "    end\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459b6a2c-864b-4e0c-873e-0b6cc1ce71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_x_method = Matrix(undef, length(benchmark_x_method_rows), n_method)\n",
    "\n",
    "for (i, v) in enumerate(benchmark_x_method_rows)\n",
    "\n",
    "    benchmark_x_method[i, :] = Float64.(v)\n",
    "\n",
    "end\n",
    "\n",
    "benchmark_x_method = DataFrame(benchmark_x_method, method_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d436a0-f4c7-4ec5-9e96-3f2693ecefce",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_x_method_path = \"benchmark_x_method.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbed1ad-ca70-4067-905f-79392774757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(benchmark_x_method_path, benchmark_x_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303533d3-59ae-46eb-b055-d1e31b91ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_x_method = read_data(benchmark_x_method_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed273e4-61a2-4fb7-a070-fe9deccf6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_like((median.(eachcol(benchmark_x_method)), names(benchmark_x_method)))[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
