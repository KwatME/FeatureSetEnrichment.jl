{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76cde750-8ccd-434f-82f8-94e84d6a6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f0dc7-21c5-4531-a5c2-6790849cf78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataIO\n",
    "using JSON\n",
    "\n",
    "using GCTGMT\n",
    "using Support\n",
    "\n",
    "using FeatureSetEnrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d507d8e-0f51-45f6-89d5-48c74cd2bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks_directory_path = \"/Users/kwat/Downloads/score_and_set/\"\n",
    "\n",
    "benchmark_ = []\n",
    "\n",
    "method_ = []\n",
    "\n",
    "benchmark_x_method = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f18ee-4e99-44b4-99d7-062cc09f342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in readdir(benchmarks_directory_path)[1:2]\n",
    "    \n",
    "    if name[1] == '.'\n",
    "\n",
    "        continue\n",
    "        \n",
    "    end\n",
    "\n",
    "    benchmark_directory_path = joinpath(benchmarks_directory_path, name)\n",
    "\n",
    "    element_, score_ = eachcol(read_data(joinpath(benchmark_directory_path, \"gene_x_score.tsv\")))\n",
    "\n",
    "    json_dict = convert(Dict{String, Vector{String}}, JSON.parse(open(joinpath(benchmark_directory_path, \"gene_set.json\"))))\n",
    "\n",
    "    gmt_path_ = map(gmt_path -> replace(gmt_path, \"..\" => \"/Users/kwat/Downloads/\"), json_dict[\"gene_sets_tested\"][1:2])\n",
    "\n",
    "    set_to_element_ = read_gmt(gmt_path_)\n",
    "\n",
    "    set_ = collect(keys(set_to_element_))\n",
    "\n",
    "    n_set = length(set_)\n",
    "\n",
    "    set_to_method_to_result = score_set_new(element_, score_, set_to_element_)\n",
    "\n",
    "    # Todo: get method only once at the top\n",
    "    method_ = collect(keys(collect(values(set_to_method_to_result))[1]))\n",
    "\n",
    "    set_x_method = Matrix(undef, n_set, length(method_))\n",
    "\n",
    "    for (set_i, (set, method_to_result)) in enumerate(set_to_method_to_result)\n",
    "\n",
    "        set_x_method_row = []\n",
    "\n",
    "        for result in values(method_to_result)\n",
    "\n",
    "            append!(set_x_method_row, result[2])\n",
    "\n",
    "        end\n",
    "\n",
    "        set_x_method[set_i, :] = set_x_method_row\n",
    "\n",
    "    end\n",
    "\n",
    "    for set in json_dict[\"gene_sets_positive\"]\n",
    "\n",
    "        push!(benchmark_, \"$name.$set\")\n",
    "\n",
    "        benchmark_x_method_row = []\n",
    "\n",
    "        for (method_i, set_score_) in enumerate(eachcol(set_x_method))\n",
    "\n",
    "            set_score_, set_ = sort_like((Float64.(set_score_), set_))\n",
    "\n",
    "            push!(benchmark_x_method_row, findfirst(set_ .== set) / n_set)\n",
    "\n",
    "        end\n",
    "\n",
    "        push!(benchmark_x_method, Float64.(benchmark_x_method_row))\n",
    "\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30410c14-09be-4c5b-b6de-f91086a8e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_x_method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
