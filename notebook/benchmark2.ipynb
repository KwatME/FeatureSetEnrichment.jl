{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368ba47c-dcfd-4973-b472-200db23a7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddca020f-33bd-4962-b5dc-420b4ce02b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559adfda-c7de-4d4a-a244-717723147b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTING = read_json(\"setting.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9049af04-3f57-4e4d-bdaa-1cde2aba6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407bff51-696e-4653-a040-5fd04801fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_x_method = read_data(SETTING[\"benchmark_x_method.tsv\"])\n",
    "\n",
    "benchmark_ = benchmark_x_method[!, 1]\n",
    "\n",
    "i_ = 2:size(benchmark_x_method)[2]\n",
    "\n",
    "method_ = names(benchmark_x_method)[i_]\n",
    "\n",
    "benchmark_x_method = Matrix(benchmark_x_method[!, i_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee90009-af49-4c27-96ad-19ce70585fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_method = \"is < ks area\"\n",
    "\n",
    "base_i = findfirst(method_ .== base_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f9798-cf35-43c4-a44b-a8a59d49e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_benchmark = length(benchmark_)\n",
    "\n",
    "n_method = length(method_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc1e22d-36c3-40ea-bc53-bd60bba4a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_x_method_metric = Matrix{Float64}(undef, n_benchmark, n_method)\n",
    "\n",
    "for benchmark_i = 1:n_benchmark\n",
    "\n",
    "    base_score = benchmark_x_method[benchmark_i, base_i]\n",
    "\n",
    "    score_ = benchmark_x_method[benchmark_i, :]\n",
    "\n",
    "    if base_score < 0\n",
    "\n",
    "        println(benchmark_[benchmark_i])\n",
    "\n",
    "        metric_ = score_ .< base_score\n",
    "\n",
    "    else\n",
    "\n",
    "        metric_ = base_score .< score_\n",
    "\n",
    "    end\n",
    "\n",
    "    benchmark_x_method_metric[benchmark_i, :] = metric_\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f114c59-48e1-498f-aff9-5037cc7659f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_better_, better_method_ =\n",
    "    sort_like(Float64.(sum(eachrow(benchmark_x_method_metric))), method_; r = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f16371-b2cf-49e2-94cd-3b1f82748abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7746f1-b663-471b-bd93-f290b1cd3002",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_style!()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401e798-8737-44d9-8413-c2e660aef8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6a5ed-4f86-4534-bd7a-11b8f437a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = benchmark_x_method[:, base_i]\n",
    "\n",
    "for (i, (n_better, method)) in enumerate(zip(n_better_, better_method_))\n",
    "\n",
    "    println(n_better / n_benchmark, \"    \", method)\n",
    "\n",
    "    method_i = findfirst(method_ .== method)\n",
    "\n",
    "    if i <= 3\n",
    "\n",
    "        display(\n",
    "            plot_x_y(\n",
    "                [[-1, 1], x],\n",
    "                [[-1, 1], benchmark_x_method[:, method_i]];\n",
    "                text_ = [benchmark_, benchmark_],\n",
    "                mode_ = [\"line\", \"markers\"],\n",
    "                layout = Layout(\n",
    "                    xaxis_title_text = method_[base_i],\n",
    "                    yaxis_title_text = method_[method_i],\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f9c79-6809-4009-91da-3129e8ec63d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"peek_benchmark.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb4ed9-25b6-44e0-b324-4eb27e7ba7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for benchmark in (\n",
    "    \"81.HAMAI_APOPTOSIS_VIA_TRAIL_UP\",\n",
    "    \"81.MILI_PSEUDOPODIA_HAPTOTAXIS_UP\",\n",
    "    \"38.GO_TRANSLATION_REGULATOR_ACTIVITY_NUCLEIC_ACID_BINDING\",\n",
    "    \"72.HALLMARK_G2M_CHECKPOINT\",\n",
    ")\n",
    "\n",
    "    peek_benchmark(benchmark)\n",
    "\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
